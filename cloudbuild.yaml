# cloudbuild.yaml

substitutions:
  _PROJECT_ID: "capstoneproject-462618"
  _GCS_BUCKET_NAME: "capstone-nasa-wildfire-sal"

# Allow up to 6 hours for long training runs
timeout: 21600s

options:
  logging: CLOUD_LOGGING_ONLY
  default_logs_bucket_behavior: REGIONAL_USER_OWNED_BUCKET

steps:
  # 1) Build the training container
  - name: "gcr.io/cloud-builders/docker"
    id: Build_Train_Image
    args:
      - build
      - -f
      - Dockerfile.train
      - -t
      - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA}
      - .

  # 2) Push the training image
  - name: "gcr.io/cloud-builders/docker"
    id: Push_Train_Image
    args:
      - push
      - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA}

  # 3) Submit Vertex AI training job (smaller machine for cost savings) and stream logs
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: Vertex_AI_Training
    entrypoint: bash
    args:
      - -c
      - |
          set -e
          echo "=== Starting Vertex AI CPU training on n1-standard-2 ==="
          JOB_NAME="wildfire-train-$${COMMIT_SHA}"
          JOB_ID=$$(gcloud ai custom-jobs create \
            --region=us-central1 \
            --display-name=$$JOB_NAME \
            --worker-pool-spec=machine-type=n1-standard-2,replica-count=1,container-image-uri=us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA} \
            --args="--bucket=${_GCS_BUCKET_NAME},--epochs=10,--batch-size=256" \
            --project=${_PROJECT_ID} \
            --format="value(name)")
          echo "Training job submitted: $$JOB_ID"
          echo "=== Streaming logs ==="
          gcloud ai custom-jobs stream-logs $$JOB_ID --region=us-central1 & 
          echo "=== Polling for job completion ==="
          while true; do
            STATE=$$(gcloud ai custom-jobs describe $$JOB_ID \
              --region=us-central1 \
              --format="value(state)")
            echo "Job state: $$STATE"
            if [[ "$$STATE" == *"SUCCEEDED"* ]]; then
              echo "Training succeeded"
              break
            elif [[ "$$STATE" == *"FAILED"* || "$$STATE" == *"CANCELLED"* ]]; then
              echo "Training failed or cancelled"
              exit 1
            fi
            sleep 60
          done

  # 4) Verify that the SavedModel directory is in GCS
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: Verify_Artifacts
    entrypoint: bash
    args:
      - -c
      - |
          echo "=== Verifying model artifacts in GCS ==="
          gsutil ls gs://${_GCS_BUCKET_NAME}/model/tf_model/saved_model.pb || exit 1
          gsutil ls gs://${_GCS_BUCKET_NAME}/model/tf_model/variables/variables.index || exit 1
          echo "Artifacts present"

  # 5a) Build the inference (serve) container
  - name: "gcr.io/cloud-builders/docker"
    id: Build_Serve_Image
    args:
      - build
      - -f
      - Dockerfile.serve
      - -t
      - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model-inference:${COMMIT_SHA}
      - .

  # 5b) Push the inference image
  - name: "gcr.io/cloud-builders/docker"
    id: Push_Serve_Image
    args:
      - push
      - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model-inference:${COMMIT_SHA}

  # 6) Register the trained model using the inference image
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: Register_Model
    entrypoint: bash
    args:
      - -c
      - |
          echo "=== Registering model in Vertex AI ==="
          gcloud ai models upload \
            --region=us-central1 \
            --display-name="wildfire-detection-model" \
            --artifact-uri="gs://${_GCS_BUCKET_NAME}/model/tf_model" \
            --container-image-uri="us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model-inference:${COMMIT_SHA}" \
            --container-predict-route="/predict" \
            --container-health-route="/health" \
            --container-ports=8080 \
            --project=${_PROJECT_ID}

  # 7) Deploy the model to a Vertex AI Endpoint (using a smaller machine for cost savings)
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: Deploy_Model
    entrypoint: bash
    args:
      - -c
      - |
          echo "=== Deploying model to Vertex AI endpoint on n1-standard-2 ==="
          ENDPOINT_ID=$$(gcloud ai endpoints list \
            --region=us-central1 \
            --filter="displayName=wildfire-prediction-endpoint" \
            --format="value(name)" --limit=1)
          if [ -z "$$ENDPOINT_ID" ]; then
            echo "Creating endpoint wildfire-prediction-endpoint"
            ENDPOINT_ID=$$(gcloud ai endpoints create \
              --region=us-central1 \
              --display-name=wildfire-prediction-endpoint \
              --format="value(name)")
          fi
          MODEL_ID=$$(gcloud ai models list \
            --region=us-central1 \
            --filter="displayName=wildfire-detection-model" \
            --format="value(name)" --limit=1)
          gcloud ai endpoints deploy-model $$ENDPOINT_ID \
            --region=us-central1 \
            --model=$$MODEL_ID \
            --display-name="deployed-wildfire-model-${COMMIT_SHA}" \
            --machine-type=n1-standard-2 \
            --traffic-split=0=100 \
            --project=${_PROJECT_ID}

# Declare the built images so Cloud Build can report them
images:
  - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA}
  - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model-inference:${COMMIT_SHA}
