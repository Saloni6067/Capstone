substitutions:
  _PROJECT_ID: "capstoneproject-462618"
  _GCS_BUCKET_NAME: "capstone-nasa-wildfire-sal"

steps:
  # 1) Build training Docker image
  - name: 'gcr.io/cloud-builders/docker'
    id: Build_Docker_Image
    args:
      - build
      - -f
      - Dockerfile.train
      - -t
      - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA}
      - .

  # 2) Push the image
  - name: 'gcr.io/cloud-builders/docker'
    id: Push_Docker_Image
    args:
      - push
      - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA}

  # 3) Submit Vertex AI custom training job and wait for success
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: Vertex_AI_Training
    entrypoint: bash
    args:
      - -c
      - |
        echo "=== Starting Vertex AI training job ==="
        JOB_NAME="wildfire-train-${SHORT_SHA}"

        JOB_ID=$(gcloud ai custom-jobs create \
          --region=us-central1 \
          --display-name=$JOB_NAME \
          --worker-pool-spec=machine-type=n1-standard-4,replica-count=1,container-image-uri=us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA} \
          --args="--bucket=${_GCS_BUCKET_NAME}" \
          --format="value(name)")

        echo "Training job submitted: $JOB_ID"

        # Stream logs
        gcloud ai custom-jobs stream-logs "$JOB_ID" --region=us-central1 &

        echo "=== Waiting for training job to complete ==="
        while true; do
          STATE=$(gcloud ai custom-jobs describe "$JOB_ID" --region=us-central1 --format="value(state)")
          echo "Job state: $STATE"
          if [[ "$STATE" == "SUCCEEDED" ]]; then
            echo "Job succeeded."
            break
          elif [[ "$STATE" == "FAILED" || "$STATE" == "CANCELLED" ]]; then
            echo "Job failed or cancelled."
            exit 1
          fi
          sleep 30
        done

  # 4) Check if model artifacts exist in GCS
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: Verify_Artifacts
    entrypoint: bash
    args:
      - -c
      - |
        echo "=== Verifying model artifacts ==="
        gsutil ls gs://${_GCS_BUCKET_NAME}/model/tf_model/saved_model.pb || exit 1
        gsutil ls gs://${_GCS_BUCKET_NAME}/model/tf_model/variables/variables.index || exit 1
        echo "Artifacts found."

  # 5) Register the model to Vertex AI
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: Register_Model
    entrypoint: bash
    args:
      - -c
      - |
        echo "=== Registering model in Vertex AI ==="
        MODEL_NAME="wildfire-detection-model"
        MODEL_URI="gs://${_GCS_BUCKET_NAME}/model/tf_model"
        IMAGE_URI="us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA}"

        gcloud ai models upload \
          --region=us-central1 \
          --display-name="$MODEL_NAME" \
          --artifact-uri="$MODEL_URI" \
          --container-image-uri="$IMAGE_URI" \
          --container-predict-route="/predict" \
          --container-health-route="/health" \
          --container-ports=8080 \
          --project=${_PROJECT_ID}

  # 6) Deploy the model to a Vertex AI endpoint
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: Deploy_Model
    entrypoint: bash
    args:
      - -c
      - |
        echo "=== Deploying model to endpoint ==="
        MODEL_NAME="wildfire-detection-model"
        ENDPOINT_NAME="wildfire-prediction-endpoint"

        # Get or create endpoint
        ENDPOINT_ID=$(gcloud ai endpoints list \
          --region=us-central1 \
          --filter="displayName=$ENDPOINT_NAME" \
          --format="value(name)" --limit=1)

        if [ -z "$ENDPOINT_ID" ]; then
          echo "Creating endpoint: $ENDPOINT_NAME"
          ENDPOINT_ID=$(gcloud ai endpoints create \
            --region=us-central1 \
            --display-name=$ENDPOINT_NAME \
            --project=${_PROJECT_ID} \
            --format="value(name)")
        else
          echo "Using existing endpoint: $ENDPOINT_ID"
        fi

        # Get model ID
        MODEL_ID=$(gcloud ai models list \
          --region=us-central1 \
          --filter="displayName=$MODEL_NAME" \
          --format="value(name)" \
          --limit=1)

        # Deploy model
        gcloud ai endpoints deploy-model $ENDPOINT_ID \
          --region=us-central1 \
          --model=$MODEL_ID \
          --display-name="deployed-$MODEL_NAME-${SHORT_SHA}" \
          --machine-type=n1-standard-2 \
          --min-replica-count=1 \
          --max-replica-count=1 \
          --traffic-split=0=100 \
          --project=${_PROJECT_ID}

images:
  - us-central1-docker.pkg.dev/${_PROJECT_ID}/capstone/ml-model:${COMMIT_SHA}

options:
  logging: CLOUD_LOGGING_ONLY
